{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77dc0947",
   "metadata": {},
   "source": [
    "# Image classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a836b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports to be used through the notebook\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd30eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df41457",
   "metadata": {},
   "source": [
    "## Data (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101f1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a transformation to apply to the items of the dataset (that are, by default, in PIL image format). The standardization will help with training.\n",
    "\n",
    "MEAN_MNIST = (0.1307,)\n",
    "STD_MNIST = (0.3081,)\n",
    "\n",
    "transform_mnist = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_MNIST, STD_MNIST)])\n",
    "\n",
    "transform_mnist_unnormalized = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='C:\\\\Users\\\\PabloHueso\\\\OneDrive - CompoSistemas, S.L\\\\Documents\\\\Master\\\\M2\\\\ENAC\\\\Adversarial-attacks\\\\Datasets', train=True,\n",
    "                                        download=True, transform=transform_mnist_unnormalized)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='C:\\\\Users\\\\PabloHueso\\\\OneDrive - CompoSistemas, S.L\\\\Documents\\\\Master\\\\M2\\\\ENAC\\\\Adversarial-attacks\\\\Datasets', train=False,\n",
    "                                       download=True, transform=transform_mnist_unnormalized)\n",
    "\n",
    "\n",
    "#trainset.__len__() # yields 60000\n",
    "#trainset.__getitem__(0) # tuple (image, class); image is a tensor 1x28x28 and class is an int\n",
    "#trainset.__getitem__(0)[0].shape #yields torch.Size([1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe02a6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train loader:  1875  | test loader:  313\n"
     ]
    }
   ],
   "source": [
    "# Trainloaders are dataset wrappers used to access them in a batched way. Of course this is very useful for NN training.\n",
    "batch_size = 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Size train loader: \", len(trainloader), \" | test loader: \", len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6a9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainloader)) # batches are lists of two tensors, one containing features and other labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06489e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdH0lEQVR4nO3de3RU1dnH8WcgMAQI4VYmjAkh1CAgoBKUglSChShSLl5RysXqskSIEOOSgNoSuSRAlQWtJRUXAhURCqLVLqQMgkFFyzUKpFUoEcJlTNGQBMQEyH7/4M2s7p0wyTAzyUny/aw1f/zOnDlnZ0/IPJzZZ2+bUkoJAACABTSq7QYAAACUozABAACWQWECAAAsg8IEAABYBoUJAACwDAoTAABgGRQmAADAMihMAACAZVCYAAAAy6AwAQAAlhG0wmTp0qUSExMjzZo1k7i4OPn444+DdSoAAFBPhATjoOvWrZPk5GRZunSp3H777fLqq6/KsGHDJCcnRzp16uT1tWVlZXLq1CkJCwsTm80WjOYBAIAAU0pJcXGxOJ1OadTo2q972IKxiF+/fv2kT58+kpmZ6dnWvXt3GT16tGRkZHh97YkTJyQqKirQTQIAADUgLy9PIiMjr/n1Ab9iUlpaKnv37pUZM2Zo2xMSEmTnzp0V9i8pKZGSkhJPLq+ToqKi/Kq4AABAzSkrK5O8vDwJCwvz6zgBL0zOnDkjly9fFofDoW13OBzidrsr7J+RkSEvvvhihe2NGjWiMAEAoI7xdxhG0D75zYYppSpt7MyZM6WwsNDzyMvLC1aTAACAxQX8ikn79u2lcePGFa6O5OfnV7iKIiJit9vFbrcHuhkAAKAOCvgVk6ZNm0pcXJy4XC5tu8vlkgEDBgT6dAAAoB4Jyu3CKSkpMn78eOnbt6/0799fli1bJsePH5fExMRgnA4AANQTQSlMxowZI999953Mnj1bTp8+LT179pRNmzZJdHR0QI6fm5sbkOOgdsXExHh9nve5fuB9bhh4nxuGqt7nQAhKYSIiMnnyZJk8eXKwDg8AAOoh7scFAACWQWECAAAsg8IEAABYBoUJAACwDAoTAABgGRQmAADAMihMAACAZVCYAAAAy6AwAQAAlkFhAgAALCNoU9LD2kaNGlVh24YNG7Q8cuRILX/wwQdBbVND9Lvf/U7LgwcP1vIzzzyj5X379gW9TQBQm7hiAgAALIPCBAAAWAaFCQAAsAwKEwAAYBkMfm0gnnjiCS0vWbKkwj47duzQssvlCmqbGqK5c+dqOTk5WcuhoaFaTklJ0fK4ceOC0i4AsAqumAAAAMugMAEAAJZBYQIAACyDMSb1VJMmTbQ8ZswYLZ88ebLCa8aPH6/lS5cuBb5hDcz999+v5aSkJC03a9bM6+tzcnIC3iZYX1pampYffPBBLZsTJB45ciTYTQJqDFdMAACAZVCYAAAAy6AwAQAAlsEYk3pq9erVWh44cKCWK5sP49SpU0FtU0PQtWtXLS9fvlzLLVu29Pr67777TsuZmZmBaRhqVWpqqpbvvvtuLSultBwdHa3lTp06afndd9/Vcs+ePf1sIWAdXDEBAACWQWECAAAsg8IEAABYBmNM6glzDMmIESO0vG3bNi1v2LAh6G1qiMy1bqoaU2L6/PPPtVxQUOB3mxB88fHxWr7jjju0bM47cvPNN2u5rKxMy1lZWVpu1aqVlm+44YZraCVM5r/PL774QssxMTFattlsWjbHBlXl008/1fKKFSu0/Prrr/t0vPqKKyYAAMAyKEwAAIBl+FyY7NixQ0aMGCFOp1NsNluF29aUUpKWliZOp1NCQ0MlPj5eDh06FKj2AgCAesznMSbnz5+Xm266SX79619XWAdERGThwoWyaNEiWblypXTt2lXmzp0rQ4cOla+++krCwsIC0mgriouL07I5D8HGjRsDer6QEP2t++Mf/6hlcw0WxpQER5cuXbS8b98+n17/0ksvadmc7wLWEBERoWVzTJc530zr1q19Ov7YsWO1/I9//EPL5t9O898/rs1Pf/pTLXfu3FnL//nPf7Rsvi9t2rTRcvfu3b2er0ePHlp+9tlntbxmzRot//jjj16PV1/5/Ns9bNgwGTZsWKXPKaVk8eLF8vzzz8t9990nIiKrVq0Sh8Mha9askUmTJvnXWgAAUK8FdIxJbm6uuN1uSUhI8Gyz2+0yaNAg2blzZ6WvKSkpkaKiIu0BAAAapoAWJm63W0REHA6Htt3hcHieM2VkZEh4eLjnERUVFcgmAQCAOiQoX1RWdq+3ua3czJkzJSUlxZOLiorqRHFifoe8ePFiLd9+++1abt68uZb9/e7Q/Drtpptu0vLRo0e1vH79er/Oh8olJiZq2dd5Dc6cORPI5iBI/vrXv2q5f//+Pr3eXDPps88+0/KOHTu0bF455kpycJhj8c6fP6/l4cOHa/nrr7/263wPPfSQlt966y0tjx49Wstr167163x1VUALk/IBYm63Wzp27OjZnp+fX+EqSjm73S52uz2QzQAAAHVUQL/KiYmJkYiICHG5XJ5tpaWlkpWVJQMGDAjkqQAAQD3k8xWTc+fOyZEjRzw5NzdXsrOzpW3bttKpUydJTk6W9PR0iY2NldjYWElPT5fmzZtXuB0OAADA5HNhsmfPHhk8eLAnl48PmThxoqxcuVKmT58uFy5ckMmTJ0tBQYH069dPtmzZUu/mMBkzZoyWzTEl3333nZbNtTD8NX36dK/Pz5kzR8vFxcUBPT+ueOCBB3za/8MPP9SyOTYJtcOcp8QcU/Lzn/9cy+a/5+zsbC2vW7dOywsXLvSzhQgGcy6uc+fOadnfMSWms2fPen3+lltu0TJjTKopPj7e6wA/m80maWlpkpaW5k+7AABAA8RaOQAAwDIoTAAAgGWw4EI1TZ06VcuzZs3yuv/777+v5dLSUr/O/8gjj2i5T58+Wj58+LCWze/IERg33nijls01kaqax2TBggVavnjxYmAaBr+Ya9+Y85SYY0rMf88rV67Usrl2lb/MKRX+dzoGEZEVK1ZoubLfw1WrVnnNDdH48eO17Os8RL4yxx6a//7N38OGiismAADAMihMAACAZVCYAAAAy2CMSTWZ85S0adNGy+ZaFlXNM+Irc2xCaGiols3vtC9cuBDQ8+OKu+++26f9s7KytGyuiWIy11R68sknfTpfZmamln/44QefXt9QxMfHa9nsN5M5T0mwx5SY5s+fr+WkpCQtN2qk/x+zsnmTtm/fHviG1XHmmJKQEP0jsWXLllo25znx1d69e7X8/fffazkmJsav49cXXDEBAACWQWECAAAsg8IEAABYBmNMrsKcn+K2227zuv+8efO0fObMGb/Ov3TpUi1HRUVp+fLly1o+cOCAX+dD9ZhjE8zv9ktKSrQ8e/ZsLZvfYb/wwgtaNufH8XWNJXNNFnONqoY45iQyMrLCtvXr12u5devWXo9hrn0T7HlKzDElvo41OnHiRIVtS5Ys8b1hDUy7du20bM5n43K5/Dp+586dtdyiRQstnz9/3q/j1xdcMQEAAJZBYQIAACyDwgQAAFgGY0yuwpyvwhxzYjLXPOjatauW8/PztXz27Fmvx0tMTNSyeb+9OQbFnC/jWpjjWHr16qXl/fv3a/n06dN+n7OuiYuL07I5BiQnJ0fL5vuyZs0aLT/00ENej+fv2h3m2ISXX37Zr+PVRea4HpGqx5SYzLE7vnr88ce1bK6JYo41uPfee/06nzkGTaTiXEuoeebngjlPCmMFr+CKCQAAsAwKEwAAYBkUJgAAwDIoTAAAgGUw+PUqPvjgAy1funRJy+aAukWLFnnNR48e1fK3337rV/vMibImTZrkdf8bb7xRy+YgThGRbt26afm5557T8qZNm3xpIkTk/vvv1/I999zj0+vNRcOeeeYZLc+YMUPL5iJgDzzwgJYb4uDXypgT41Xl448/1vLy5cu1PHLkSC2PGjXKp/Ob/7bM923x4sVa7tSpk9fjffrpp17PjyvefvttLU+ZMqVGz2+z2bS8c+fOGj2/VXHFBAAAWAaFCQAAsAwKEwAAYBmMMbmK48ePa/m3v/2tll988UUtN23a1OvxunTp4jX7avr06X69/tSpUxW2mWNKXn31Vb/O0RCZEyiZYxHMCZVM5liGJ554QsvmIl/mIoAmFgWrnK+LIw4YMEDLP/vZz3w6vrmopzlGzPx70qNHDy3/5Cc/8Xr8zZs3a3natGle24crnn76aS2bYzw++uijoJ7fnEDx+++/D+r56gqumAAAAMugMAEAAJZBYQIAACyjQY4xMb/nLykpqbCPuSjfggULtLxhwwYtjxgxwus5f/Ob32jZnDOkKl999ZWWqxr/UVBQoOX3339fy6WlpRVeY86ZAd81a9bMr9fPmjVLy4WFhVo259cxF140mfNrNESVLZg5e/ZsLU+dOlXLvi7yZ1qyZImW33jjDS1/8cUXXl9vLiJqt9u97r9s2TItV7VIKK4w56d66623aqklVzBX1BVcMQEAAJbhU2GSkZEht956q4SFhUmHDh1k9OjRFf4nr5SStLQ0cTqdEhoaKvHx8XLo0KGANhoAANRPPhUmWVlZMmXKFPn888/F5XLJpUuXJCEhQbslceHChbJo0SJ55ZVXZPfu3RIRESFDhw6V4uLigDceAADULzZl3kjtg//+97/SoUMHycrKkjvuuEOUUuJ0OiU5OVlSU1NF5Mr4DYfDIQsWLKhyPRcRkaKiIgkPD5fo6OirrmeRm5t7rU0WEZHY2NgKP4cp0N/RtmrVSssHDx7UcmRkpJaPHDmi5bvuukvL/vaBFZjrupis+DOePn1ayxEREVr2dX6MPXv2aHnHjh1aHjZsmJa7d+/u9Xhz5szRclpamk/tCYa68D5fd911WjbXwvLVyZMntWyOZTCZYxuGDBmiZXPMy7/+9S8t9+7d28cWBl5deJ9r2/z587X8+OOPa7lPnz5azsvLC3qbfOXtfS4rK5Njx45JYWFhhc88X/g1xqR8YF7btm1F5MovntvtloSEBM8+drtdBg0axOJEAACgStf83wKllKSkpMjAgQOlZ8+eIiLidrtFRMThcGj7OhwOOXbsWKXHKSkp0e6KKSoqutYmAQCAOu6ar5gkJSXJl19+WentVeZSzkqpCtvKZWRkSHh4uOdR1e2PAACg/rqmKyZPPfWUvPfee7Jjxw5tbET59+1ut1s6duzo2Z6fn1/hKkq5mTNnSkpKiicXFRUFvTg5fPhwUI9fGXPtC3NMiclcI4XvZ61h5cqVWjbXLPJ1yFZcXJyW+/bt6/V4Zv7000+1nJGR4dP5cYU5JqSmmX8fq5pH5aWXXgpiaxAsTqdTyydOnNCyFceU1AafrpgopSQpKUk2btwo27ZtqzAIJiYmRiIiIsTlcnm2lZaWSlZWVoVFsMrZ7XZp1aqV9gAAAA2TT1dMpkyZImvWrJG//e1vEhYW5hlTEh4eLqGhoWKz2SQ5OVnS09MlNjZWYmNjJT09XZo3by5jx44Nyg8AAADqD58Kk8zMTBERiY+P17avWLFCHn30URG5cmn7woULMnnyZCkoKJB+/frJli1bJCwsLCANBgAA9ZdPhUl1vj+32WySlpZmifkTrOTpp5/2af+srKwgtQT+2Lhxo5bNMSY1fX5zzZfK1n2C9Vx//fVaNufDMedwmjt3rpb/8pe/BKdhCKqqxozhCtbKAQAAlkFhAgAALIPCBAAAWIZ/C0Lgqsx5S0aNGuV1/9WrVwezOQiQ3bt3a3nGjBlaDvQ8Iu+++66WH3vsMS2fO3cuoOdDzRg4cKCWzfW7zDWXXn/99aC3CTWvS5cuXvPRo0drsjmWwRUTAABgGRQmAADAMihMAACAZTDGJEhatmypZXOtG3OtHNY4qZtefvllLW/atEnLEyZM0PLEiRO1/M0332h5zpw5Wt66dauWmaekYZo6daqW33jjDS1nZ2fXYGsQKOYYkoY6psTEFRMAAGAZFCYAAMAyKEwAAIBlMMYkSHbt2qXl7t2711JLEEzmfBOHDh3ScmpqqteMhql8ZfZyZ8+e1XLr1q21bI5VMseojRkzJmBtQ/DYbDavGVdwxQQAAFgGhQkAALAMChMAAGAZjDEBgBq2efNmLScnJ2v53nvv1fKyZcu0vGXLlqC0C8GllNKyOfbQXGMtJycn6G2yIq6YAAAAy6AwAQAAlkFhAgAALIPCBAAAWAaDXwGglr355pteM+qnJk2aaDkkhI9kEa6YAAAAC6EwAQAAlkFhAgAALIMvtAAAqAHbtm3TsjnBWkFBQU02x7K4YgIAACyDwgQAAFgGhQkAALAMxpgAAFADVq1a5TXjCq6YAAAAy/CpMMnMzJTevXtLq1atpFWrVtK/f3/54IMPPM8rpSQtLU2cTqeEhoZKfHy8HDp0KOCNBgAA9ZNPhUlkZKTMnz9f9uzZI3v27JE777xTRo0a5Sk+Fi5cKIsWLZJXXnlFdu/eLRERETJ06FApLi4OSuMBAED9YlNKKX8O0LZtW/n9738vjz32mDidTklOTpbU1FQRESkpKRGHwyELFiyQSZMmVet4RUVFEh4eLtHR0dKoEd80AQBQF5SVlcmxY8eksLBQWrVqdc3HueZP/suXL8vatWvl/Pnz0r9/f8nNzRW32y0JCQmefex2uwwaNEh27tx51eOUlJRIUVGR9gAAAA2Tz4XJgQMHpGXLlmK32yUxMVHeeecd6dGjh7jdbhERcTgc2v4Oh8PzXGUyMjIkPDzc84iKivK1SQAAoJ7wuTC54YYbJDs7Wz7//HN58sknZeLEiZKTk+N53mazafsrpSps+18zZ86UwsJCzyMvL8/XJgEAgHrC53lMmjZtKtdff72IiPTt21d2794tS5Ys8Ywrcbvd0rFjR8/++fn5Fa6i/C+73S52u93XZgAAgHrI79GlSikpKSmRmJgYiYiIEJfL5XmutLRUsrKyZMCAAf6eBgAANAA+XTF57rnnZNiwYRIVFSXFxcWydu1a+eijj2Tz5s1is9kkOTlZ0tPTJTY2VmJjYyU9PV2aN28uY8eODVb7AQBAPeJTYfLtt9/K+PHj5fTp0xIeHi69e/eWzZs3y9ChQ0VEZPr06XLhwgWZPHmyFBQUSL9+/WTLli0SFhZW7XOU371cVlbmS9MAAEAtKv/c9nMWEv/nMQm0EydOcGcOAAB1VF5enkRGRl7z6y1XmJSVlcmpU6ckLCxMiouLJSoqSvLy8vyarKUhKyoqog/9RB/6jz4MDPrRf/Sh/67Wh0opKS4uFqfT6dcEqZZbXbhRo0aeSqv8NuPytXlw7ehD/9GH/qMPA4N+9B996L/K+jA8PNzv4zLnOwAAsAwKEwAAYBmWLkzsdrvMmjWLCdj8QB/6jz70H30YGPSj/+hD/wW7Dy03+BUAADRclr5iAgAAGhYKEwAAYBkUJgAAwDIoTAAAgGVYtjBZunSpxMTESLNmzSQuLk4+/vjj2m6SZWVkZMitt94qYWFh0qFDBxk9erR89dVX2j5KKUlLSxOn0ymhoaESHx8vhw4dqqUWW19GRoZnYcpy9GH1nDx5UsaNGyft2rWT5s2by8033yx79+71PE8/enfp0iV54YUXJCYmRkJDQ6VLly4ye/Zsbf0w+lC3Y8cOGTFihDidTrHZbPLuu+9qz1env0pKSuSpp56S9u3bS4sWLWTkyJFy4sSJGvwpap+3frx48aKkpqZKr169pEWLFuJ0OmXChAly6tQp7RgB6UdlQWvXrlVNmjRRr732msrJyVHTpk1TLVq0UMeOHavtplnSXXfdpVasWKEOHjyosrOz1fDhw1WnTp3UuXPnPPvMnz9fhYWFqbffflsdOHBAjRkzRnXs2FEVFRXVYsutadeuXapz586qd+/eatq0aZ7t9GHVvv/+exUdHa0effRR9c9//lPl5uaqrVu3qiNHjnj2oR+9mzt3rmrXrp36+9//rnJzc9X69etVy5Yt1eLFiz370Ie6TZs2qeeff169/fbbSkTUO++8oz1fnf5KTExU1113nXK5XGrfvn1q8ODB6qabblKXLl2q4Z+m9njrx7Nnz6ohQ4aodevWqX//+9/qs88+U/369VNxcXHaMQLRj5YsTG677TaVmJiobevWrZuaMWNGLbWobsnPz1ciorKyspRSSpWVlamIiAg1f/58zz4//vijCg8PV3/+859rq5mWVFxcrGJjY5XL5VKDBg3yFCb0YfWkpqaqgQMHXvV5+rFqw4cPV4899pi27b777lPjxo1TStGHVTE/UKvTX2fPnlVNmjRRa9eu9exz8uRJ1ahRI7V58+Yaa7uVVFbgmXbt2qVExHPRIFD9aLmvckpLS2Xv3r2SkJCgbU9ISJCdO3fWUqvqlsLCQhERadu2rYiI5Obmitvt1vrUbrfLoEGD6FPDlClTZPjw4TJkyBBtO31YPe+995707dtXHnzwQenQoYPccsst8tprr3mepx+rNnDgQPnwww/l66+/FhGRL774Qj755BO55557RIQ+9FV1+mvv3r1y8eJFbR+n0yk9e/akT70oLCwUm80mrVu3FpHA9aPlFvE7c+aMXL58WRwOh7bd4XCI2+2upVbVHUopSUlJkYEDB0rPnj1FRDz9VlmfHjt2rMbbaFVr166Vffv2ye7duys8Rx9Wz9GjRyUzM1NSUlLkueeek127dsnUqVPFbrfLhAkT6MdqSE1NlcLCQunWrZs0btxYLl++LPPmzZNHHnlERPhd9FV1+svtdkvTpk2lTZs2Ffbhc6dyP/74o8yYMUPGjh3rWcgvUP1oucKkXPnKwuWUUhW2oaKkpCT58ssv5ZNPPqnwHH16dXl5eTJt2jTZsmWLNGvW7Kr70YfelZWVSd++fSU9PV1ERG655RY5dOiQZGZmyoQJEzz70Y9Xt27dOlm9erWsWbNGbrzxRsnOzpbk5GRxOp0yceJEz370oW+upb/o08pdvHhRHn74YSkrK5OlS5dWub+v/Wi5r3Lat28vjRs3rlBd5efnV6h4oXvqqafkvffek+3bt0tkZKRne0REhIgIferF3r17JT8/X+Li4iQkJERCQkIkKytL/vCHP0hISIinn+hD7zp27Cg9evTQtnXv3l2OHz8uIvwuVsezzz4rM2bMkIcfflh69eol48ePl6effloyMjJEhD70VXX6KyIiQkpLS6WgoOCq++CKixcvykMPPSS5ubnicrk8V0tEAtePlitMmjZtKnFxceJyubTtLpdLBgwYUEutsjallCQlJcnGjRtl27ZtEhMToz0fExMjERERWp+WlpZKVlYWffr/fvGLX8iBAwckOzvb8+jbt6/86le/kuzsbOnSpQt9WA233357hVvVv/76a4mOjhYRfher44cffpBGjfQ/zY0bN/bcLkwf+qY6/RUXFydNmjTR9jl9+rQcPHiQPv0f5UXJ4cOHZevWrdKuXTvt+YD1ow+DdGtM+e3Cy5cvVzk5OSo5OVm1aNFCffPNN7XdNEt68sknVXh4uProo4/U6dOnPY8ffvjBs8/8+fNVeHi42rhxozpw4IB65JFHGvTthdXxv3flKEUfVseuXbtUSEiImjdvnjp8+LB68803VfPmzdXq1as9+9CP3k2cOFFdd911ntuFN27cqNq3b6+mT5/u2Yc+1BUXF6v9+/er/fv3KxFRixYtUvv37/fcLVKd/kpMTFSRkZFq69atat++ferOO+9scLcLe+vHixcvqpEjR6rIyEiVnZ2tfdaUlJR4jhGIfrRkYaKUUn/6059UdHS0atq0qerTp4/n1ldUJCKVPlasWOHZp6ysTM2aNUtFREQou92u7rjjDnXgwIHaa3QdYBYm9GH1vP/++6pnz57Kbrerbt26qWXLlmnP04/eFRUVqWnTpqlOnTqpZs2aqS5duqjnn39e++NPH+q2b99e6d/AiRMnKqWq118XLlxQSUlJqm3btio0NFT98pe/VMePH6+Fn6b2eOvH3Nzcq37WbN++3XOMQPSjTSmlfL2cAwAAEAyWG2MCAAAaLgoTAABgGRQmAADAMihMAACAZVCYAAAAy6AwAQAAlkFhAgAALIPCBAAAWAaFCQAAsAwKEwAAYBkUJgAAwDIoTAAAgGX8H4fEmWxBV0laAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:      4             6             9             7 \n",
      "\n",
      "Image shape (number of channels, height, width): (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img * STD_MNIST[0] + MEAN_MNIST[0]  # Proper unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')  # MNIST is grayscale + original tensor shape is (1,28,28) so  np.transpose(img, (1, 2, 0)) gets it to shape (28,28,1) \n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:4], labels[:4]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('Labels:     ','             '.join(f'{labels[j]}' for j in range(4)), '\\n')\n",
    "print(f'Image shape (number of channels, height, width): {tuple(images[0].shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cf4e3",
   "metadata": {},
   "source": [
    "## First model\n",
    "Note that this model outputs logits; not probabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a901506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, 10, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(1690, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial shape is [B, 1, 28, 28]\n",
    "        x = self.conv(x)\n",
    "        # After convoluting, shape is [B, 10, 26, 26]\n",
    "        x = nn.ReLU()(x)\n",
    "        # After ReLU, shape is [B, 10, 26, 26] (it's an element-wise operation)\n",
    "        x = self.pool(x)\n",
    "        # After pooling, shape is [B, 10, 13, 13]\n",
    "        x = nn.Flatten()(x)\n",
    "        # After flattening shape is [B, 1690] (naturally, 1690 = 10x13x13)\n",
    "        x = self.fc(x)\n",
    "        # Final shape is [B, 10] (we have logits for 10 possible classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29637a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96aa7e8",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8666fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels=1\n",
    "output_shape=10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def build_and_train_model(archi=SimpleCNN, trainloader=trainloader, input_shape=input_channels, output_shape=output_shape, optimizer=optim.SGD, criterion=criterion, device=\"cpu\", n_epochs=20, lr=0.01):\n",
    " \n",
    "  # When building a model, you assign it to a particular device by setting: model = model.to(device); device is indicated by a string, like \"cpu\" our \"cuda:0\"\n",
    "  model = archi(input_shape,output_shape).to(device)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "  for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "      # Same as for the model, you have to assign a device for your inputs and your label, for example: x = x.to(device)\n",
    "      inputs, labels = x.to(device), y.to(device)\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch} / {n_epochs} | Loss: {running_loss / len(trainloader)}')\n",
    "    running_loss = 0.0\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf1da94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 20 | Loss: 0.2808903154010574\n",
      "Epoch 1 / 20 | Loss: 0.10869014572103819\n",
      "Epoch 2 / 20 | Loss: 0.07820359647180886\n",
      "Epoch 3 / 20 | Loss: 0.06514626938644796\n",
      "Epoch 4 / 20 | Loss: 0.05589691630685702\n",
      "Epoch 5 / 20 | Loss: 0.05097346098938336\n",
      "Epoch 6 / 20 | Loss: 0.04723241805881262\n",
      "Epoch 7 / 20 | Loss: 0.0428250704837963\n",
      "Epoch 8 / 20 | Loss: 0.039861478072001286\n",
      "Epoch 9 / 20 | Loss: 0.03756430459135833\n",
      "Epoch 10 / 20 | Loss: 0.03545104061832341\n",
      "Epoch 11 / 20 | Loss: 0.03348648899283726\n",
      "Epoch 12 / 20 | Loss: 0.030768845820279483\n",
      "Epoch 13 / 20 | Loss: 0.02967828694120981\n",
      "Epoch 14 / 20 | Loss: 0.0276612089800726\n",
      "Epoch 15 / 20 | Loss: 0.026203384472705267\n",
      "Epoch 16 / 20 | Loss: 0.02476732923233455\n",
      "Epoch 17 / 20 | Loss: 0.023499608637047156\n",
      "Epoch 18 / 20 | Loss: 0.022434070594934748\n",
      "Epoch 19 / 20 | Loss: 0.021652104863669957\n",
      "Training with cuda:0 lasts: 2.56 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = build_and_train_model(device=device)\n",
    "print(f\"Training with {device} lasts: {np.round((time.time()-start_time)/60,2)} minutes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3006120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once your model has been trained, you have to evaluate it on the test set.\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "      for X, y in dataloader:\n",
    "          pred = model(X.to(device))\n",
    "          loss = loss_fn(pred, y.to(device)).item()\n",
    "          test_loss += loss\n",
    "          # Your current output is the for each class to be the right one.\n",
    "          prediction = pred.argmax(axis=1)\n",
    "          # To compute the accuracy score, we need to know how many correct predictions we got.\n",
    "          correct += (prediction == y.to(device)).sum().item()\n",
    "          ###\n",
    "    test_loss /= len(dataloader)\n",
    "    correct /= len(dataloader.dataset)\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f72c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Accuracy: 98.4%, Avg loss: 0.060009 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = test_loop(testloader, model, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88564cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Models/MNISTsmall-unnormalized.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23bbb9",
   "metadata": {},
   "source": [
    "## Second model with final softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2554fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNprobas(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, 10, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(1690, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial shape is [B, 1, 28, 28]\n",
    "        x = self.conv(x)\n",
    "        # After convoluting, shape is [B, 10, 26, 26]\n",
    "        x = nn.ReLU()(x)\n",
    "        # After ReLU, shape is [B, 10, 26, 26] (it's an element-wise operation)\n",
    "        x = self.pool(x)\n",
    "        # After pooling, shape is [B, 10, 13, 13]\n",
    "        x = nn.Flatten()(x)\n",
    "        # After flattening shape is [B, 1690] (naturally, 1690 = 10x13x13)\n",
    "        x = self.fc(x)\n",
    "        # Final shape is [B, 10] (we have logits for 10 possible classes)\n",
    "        x = nn.functional.softmax(x, dim=1)   \n",
    "        # Does not change shape either\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EntornoDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
